{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47eeba14-d3a6-41a9-82c3-5b097534a7e6",
   "metadata": {},
   "source": [
    "# Name: Mohammad Javad Noroozi\n",
    "# Student Number: 99102434\n",
    "# HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19a1c3",
   "metadata": {},
   "source": [
    "### import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cd6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41badba-b436-496a-b7b6-b2852712dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/01 23:23:16 WARN Utils: Your hostname, javad-IdeaPad-Gaming-3-15IAH7 resolves to a loopback address: 127.0.1.1; using 192.168.137.8 instead (on interface enp48s0)\n",
      "24/02/01 23:23:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/01 23:23:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.find()\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"HW1\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b5444",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4eec883-f41e-4c88-b3d6-163ee5b8a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rdd = sc.textFile(\"twitter_data_v2.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b3c30",
   "metadata": {},
   "source": [
    "### Downsampling (If your RAM memory is low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093bb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rdd = tweets_rdd.sample(False, 0.1, seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7d755",
   "metadata": {},
   "source": [
    "### Show a sample of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f18c54-ddcb-4e8d-a070-11c3250579a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_rdd.takeSample(False, 1, 19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c45732",
   "metadata": {},
   "source": [
    "### Show size of data (No. tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52127dd1-6292-410c-a258-133e19a320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_rdd.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470c4cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users = list(set(tweets_rdd.map(lambda x: json.loads(x)[\"user\"].get('id')).collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee7045",
   "metadata": {},
   "source": [
    "### Define Parameters for the Primary Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a28c55-4018-4f4b-9748-a6bc7580c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "owner_s = 1\n",
    "\n",
    "# following parameters should not be equal to owner_s\n",
    "rep_to_s = 0.2\n",
    "rep_from_s = 0.9\n",
    "\n",
    "ret_to_s = 0.5\n",
    "ret_from_s = 1.5\n",
    "\n",
    "qut_to_s = 0.6\n",
    "qut_from_s = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff25b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e151c1db",
   "metadata": {},
   "source": [
    "### Define functions for primary and secondary ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58ba664-f604-402e-b083-b3e38224b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_user_tid_score(tid, uid, type, origin_tid, origin_uid):\n",
    "    ''' This function used for calculate primary rating matrix.\n",
    "    \n",
    "    This function get some information of a tweet and Returns\n",
    "    the score that two users (the user who posted this tweet\n",
    "    and the user who posted the original tweet and has now\n",
    "    been replied to, retweeted, or quoted by this tweet)\n",
    "    give to these two tweets FOR EACH USER.\n",
    "\n",
    "    The output is a list of tuples, where each tuple contains\n",
    "    a user ID and a list of tweets that have been rated (along\n",
    "    with the value of the rating).\n",
    "    Output format: [((u_i, ((t_j, s_ij),)) ...]\n",
    "    '''\n",
    "    origin_tid = [i for i in origin_tid if i is not None]\n",
    "    origin_uid = [i for i in origin_uid if i is not None]\n",
    "\n",
    "    if not origin_tid or not origin_uid:\n",
    "        return [(uid, [(tid, owner_s)])]\n",
    "\n",
    "    to_s = rep_to_s if type == \"replied\" else\\\n",
    "           ret_to_s if type == \"retweeted\" else\\\n",
    "           qut_to_s if type == \"quoted\" else\\\n",
    "           0\n",
    "    from_s = rep_from_s if type == \"replied\" else\\\n",
    "             ret_from_s if type == \"retweeted\" else\\\n",
    "             qut_from_s if type == \"quoted\" else\\\n",
    "             0\n",
    "\n",
    "    return [(uid, [(tid, owner_s), (origin_tid[0], from_s)]),\n",
    "            (origin_uid[0], [(tid, to_s)]),\n",
    "           ]\n",
    "\n",
    "\n",
    "def to_tid_user_score(tid, uid, type, origin_tid, origin_uid):\n",
    "    ''' This function used for secondary rating.\n",
    "\n",
    "    This function get some information of a tweet and Returns\n",
    "    the score that two users (the user who posted this tweet\n",
    "    and the user who posted the original tweet and has now\n",
    "    been replied to, retweeted, or quoted by this tweet)\n",
    "    give to these two tweets FOR EACH TWEET.\n",
    "\n",
    "    The output is a list of tuples, where each tuple contains\n",
    "    a tweet ID and a tuple list of users rate to it (along with\n",
    "    the value of the rating).\n",
    "    Output format: [(u_i, ((t_j, s_ij), ...)), ...]\n",
    "    '''\n",
    "    origin_tid = [i for i in origin_tid if i is not None]\n",
    "    origin_uid = [i for i in origin_uid if i is not None]\n",
    "\n",
    "    if not origin_tid or not origin_uid:\n",
    "        return [(tid, ((uid, owner_s),))]\n",
    "\n",
    "    to_s = rep_to_s if type == \"replied\" else\\\n",
    "           ret_to_s if type == \"retweeted\" else\\\n",
    "           qut_to_s if type == \"quoted\" else\\\n",
    "           0\n",
    "    from_s = rep_from_s if type == \"replied\" else\\\n",
    "             ret_from_s if type == \"retweeted\" else\\\n",
    "             qut_from_s if type == \"quoted\" else\\\n",
    "             0\n",
    "\n",
    "    return [(tid, ((uid, owner_s), (origin_uid[0], to_s),)),\n",
    "            (origin_tid[0], ((uid, from_s),)),\n",
    "           ]\n",
    "\n",
    "\n",
    "def extract_tuples(tweet_info, func):\n",
    "    '''\n",
    "    This function extract some information of tweet and send it\n",
    "    to one of the following funcions and return their results:\n",
    "    - to_user_tid_score\n",
    "    - to_tid_user_score\n",
    "    '''\n",
    "    return func(\n",
    "        tweet_info.get('id'),\n",
    "        tweet_info[\"user\"].get('id'),\n",
    "        tweet_info.get('tweet_type'),\n",
    "        [\n",
    "            tweet_info.get('in_reply_to_status_id_str', None),\n",
    "            tweet_info.get('quoted_status', {}).get('id'),\n",
    "            tweet_info.get('retweeted_status', {}).get('id'),\n",
    "        ],\n",
    "        [\n",
    "            tweet_info.get('in_reply_to_user_id_str', None),\n",
    "            tweet_info.get('quoted_status', {}).get('user', {}).get('id'),\n",
    "            tweet_info.get('retweeted_status', {}).get('user', {}).get('id'),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_relations2(x):\n",
    "    '''\n",
    "    This function extracts the MAX_REALTION strongest relationships\n",
    "    between users who interacted with this tweet.\n",
    "    \n",
    "    x contains the tweet_id (tid) and a list of tuples. Each tuple\n",
    "    contains a user_id (u) and its interaction with the tweet (score\n",
    "    given to the tweet).\n",
    "    x: (tid, [(u1, s1), ...])\n",
    "\n",
    "    The output is a list that each element of it, contains the user_id\n",
    "    (u1) and a list of tuples. Each tuple contains a tweet_id (tid), \n",
    "    second user_id that has relation to u1 (called u2), and the score\n",
    "    given by each of these two users to this tweet (s1 and s2 respectively)\n",
    "    output: \n",
    "    [(u1, [(tid, u2, s1, s2),\n",
    "            (tid, u3, s1, s3),\n",
    "            ...\n",
    "           ]),\n",
    "     (u2, [(tid, u1, s2, s1),\n",
    "            (tid, u3, s2, s3),\n",
    "            ...\n",
    "                  ]),\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    '''\n",
    "    MAX_REALTION = 10\n",
    "\n",
    "    tid, user_score = x\n",
    "    relations = []\n",
    "    if len(user_score) > MAX_REALTION:\n",
    "        user_score = [(u1, s1) for (u1, s1) in user_score if s1 > rep_to_s]\n",
    "    if len(user_score) > MAX_REALTION:\n",
    "        user_score = [(u1, s1) for (u1, s1) in user_score if s1 > ret_to_s]\n",
    "\n",
    "\n",
    "    for (u1, s1) in user_score:\n",
    "        u1_relations = []\n",
    "        for (u2, s2) in user_score:\n",
    "            if u1 != u2 and s1 > rep_to_s:\n",
    "                u1_relations.append((tid, u2, s1, s2))\n",
    "\n",
    "        # if len(u1_relations) > MAX_REALTION:\n",
    "        #     relations.append(\n",
    "        #         (u1, sorted(u1_relations, key=lambda x: -x[2]*x[3])[:10]))\n",
    "        # else:\n",
    "        relations.append((u1, u1_relations))\n",
    "        \n",
    "    return relations\n",
    "\n",
    "\n",
    "\n",
    "def extract_relations(x):\n",
    "    '''\n",
    "    This function extracts the MAX_REALTION strongest relationships\n",
    "    between users who interacted with this tweet.\n",
    "    \n",
    "    x contains the tweet_id (tid) and a list of tuples. Each tuple\n",
    "    contains a user_id (u) and its interaction with the tweet (score\n",
    "    given to the tweet).\n",
    "    x: (tid, [(u1, s1), ...])\n",
    "\n",
    "    The output is a list that each element of it, contains the user_id\n",
    "    (u1) and a list of tuples. Each tuple contains a tweet_id (tid), \n",
    "    second user_id that has relation to u1 (called u2), and the score\n",
    "    given by each of these two users to this tweet (s1 and s2 respectively)\n",
    "    output: \n",
    "    [\n",
    "        (u1,   (\n",
    "                    ((tid, s1), [(u2, s2),\n",
    "                                (u3, s3),\n",
    "                                ...\n",
    "                                ]\n",
    "                    ),\n",
    "                )\n",
    "        ),\n",
    "        (u2,   (\n",
    "                    ((tid, s2), [(u1, s1),\n",
    "                                (u3, s3),\n",
    "                                ...\n",
    "                                ]\n",
    "                    ),\n",
    "                )\n",
    "        ),\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    '''\n",
    "    # MAX_REALTION = 10\n",
    "\n",
    "\n",
    "    # if len(user_score) > MAX_REALTION:\n",
    "    #     user_score = [(u1, s1) for (u1, s1) in user_score if s1 > rep_to_s]\n",
    "    # if len(user_score) > MAX_REALTION:\n",
    "    #     user_score = [(u1, s1) for (u1, s1) in user_score if s1 > ret_to_s]\n",
    "\n",
    "    tid, user_score = x\n",
    "    relations = []\n",
    "\n",
    "    for (u1, s1) in user_score:\n",
    "        if s1 > rep_to_s:\n",
    "            u1_relations = []\n",
    "            for (u2, s2) in user_score:\n",
    "                if u1 != u2:\n",
    "                    u1_relations.append((u2, s2))\n",
    "\n",
    "            relations.append((u1, (((tid, s1), u1_relations), )))\n",
    "        \n",
    "    return relations\n",
    "\n",
    "\n",
    "def select_best(x):\n",
    "    '''\n",
    "    This function select 25 strongest relations from relations \n",
    "    exist in x.\n",
    "    x contains the user_id (u1) and a list of tuples. Each tuple\n",
    "    contains a tweet_id (tid), second user_id that has relation \n",
    "    to u1 (called u2), and the score given by each of these two\n",
    "    users to this tweet (s1 and s2 respectively)\n",
    "\n",
    "    x: (u1, ( ((tid, s1),   [(uj,sj),]), ...))\n",
    "    '''\n",
    "    u1 = x[0]\n",
    "    tid_in_relation_with_score, users_in_relation = zip(*x[1])\n",
    "    # u1, relations = x\n",
    "    if relations:\n",
    "        th = rep_to_s\n",
    "        while len(relations) > 25:\n",
    "            new_relations = [r for r in relations if r[2]*r[3] > th]\n",
    "            if len(new_relations) < 15:\n",
    "                break\n",
    "            relations = new_relations\n",
    "            th *= 1.1\n",
    "\n",
    "    return (u1, relations)\n",
    "\n",
    "\n",
    "def find_user_interests(x):\n",
    "    '''\n",
    "    x:  (u1,   (\n",
    "                    ((tid, s1), [(u2, s2),\n",
    "                                (u3, s3),\n",
    "                                ...\n",
    "                                ]\n",
    "                    ),\n",
    "                )\n",
    "        ),\n",
    "\n",
    "    note: s1 > rep_to_s\n",
    "\n",
    "    x: (u1, ( ((tid, s1),   [(uj,sj),]), ...))\n",
    "    tid_in_relation_with_score: ((tid_i, s1_i), ...)\n",
    "    users_in_relation: ([(uj, sj), ...], [(uk, sk), ...], ...)\n",
    "    '''\n",
    "        # x: (u1, ( ((tid, s1),   [(uj,sj),]), ...))\n",
    "\n",
    "    u1 = x[0]\n",
    "\n",
    "    tid_in_relation_with_score, users_in_relation = zip(*x[1])\n",
    "    interest = []\n",
    "    for i, (tid, s1_i) in enumerate(tid_in_relation_with_score):\n",
    "        if s1_i != owner_s:\n",
    "            interest.append((u1, (tid, s1_i)))\n",
    "        if s1_i > rep_to_s:\n",
    "            for (uj, sj) in users_in_relation[i]:\n",
    "                for k, (tid2, s1_k) in enumerate(tid_in_relation_with_score):\n",
    "                    if i != k and sj != owner_s:\n",
    "                        interest.append((uj, {tid2: s1_i*sj*s1_k}))\n",
    "\n",
    "    return interest\n",
    "\n",
    "def find_user_interests3(x):\n",
    "    '''\n",
    "    x:  (u1,   (\n",
    "                    ((tid), [(u2),\n",
    "                            (u3),\n",
    "                            ...\n",
    "                            ]\n",
    "                    ),\n",
    "                )\n",
    "        ),\n",
    "        \n",
    "        x: (u1, ( (tid,   [uj, ]), ...))\n",
    "\n",
    "        tid_in_relation: ((tid_i), ...)\n",
    "        users_in_relation: ([(uj), ...], [(uk, sk), ...], ...)\n",
    "    '''\n",
    "        # x: (u1, ( ((tid, s1),   [(uj,sj),]), ...))\n",
    "\n",
    "    u1 = x[0]\n",
    "\n",
    "    tid_in_relation_with_score, users_in_relation = zip(*x[1])\n",
    "    interest = {}\n",
    "    for i, (tid, s1_i) in enumerate(tid_in_relation_with_score):\n",
    "        if s1_i > rep_to_s:\n",
    "            for (uj, sj) in users_in_relation[i]:\n",
    "                for k, (tid2, s1_k) in enumerate(tid_in_relation_with_score):\n",
    "                    if i != k:\n",
    "                        interest[uj] = interest.get(uj, set()).union({tid2})\n",
    "\n",
    "\n",
    "def find_user_interests2(x, user_scores):\n",
    "    ''' \n",
    "        user_scores: {ui: [(t_j, s_ij), ...]}\n",
    "        x: (u1, ((tid, uj, s1, sj), ...))\n",
    "    '''\n",
    "    th = 0.05\n",
    "    u, relations = x\n",
    "    interest = {}\n",
    "    if relations:\n",
    "        for (tid, uj, s1, s2) in relations:\n",
    "            interest[tid] = interest.get(tid, 0) + s1\n",
    "            for (t, s) in user_scores.get(uj, []):\n",
    "                interest[t] = interest.get(t, 0) + s1*s2*s\n",
    "\n",
    "    if interest:\n",
    "        max_interest = max(interest.values())\n",
    "        th = 0.05 * max_interest\n",
    "        while len(interest) > 100:\n",
    "            interest = {t:i for t,i in interest.items() if i > th}\n",
    "            th *= 1.1\n",
    "        return (u, interest)\n",
    "    return (u,{})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472e6beb-5ac7-4a17-9eac-69359b8074c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 23:23:34.824573\n"
     ]
    }
   ],
   "source": [
    "startt = datetime.datetime.now()\n",
    "print(startt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f8826",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6891164e-80c0-4780-86d1-b903ed9fd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [((u_i, ((t_j, s_ij),)), ...]\n",
    "# user_tid_score_rdd = tweets_rdd.flatMap(\n",
    "#     lambda x: extract_tuples(json.loads(x), func=to_user_tid_score))\n",
    "\n",
    "# # [(u_i, ((t_j, s_ij), ...)), ...]\n",
    "# user_tids_scores_rdd = user_tid_score_rdd.reduceByKey(\n",
    "#     lambda x, y: x if not x.extend(y) else x)\n",
    "\n",
    "# user_scores_list = user_tids_scores_rdd.collect()\n",
    "\n",
    "# user_scores_dict = dict(user_scores_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160b5e0e-cf48-41cb-86d5-fc4df33c7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [(tid, [(u, s)]), ...]\n",
    "# tid_user_score_rdd = tweets_rdd.flatMap(lambda x: extract_tuples(json.loads(x), func=to_tid_user_score))\n",
    "\n",
    "# # [(tid, [(u, s), ...]), ...]\n",
    "# tid_users_scores_rdd = tid_user_score_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# # [(u1, [(tid, u2, s1, s2)])]\n",
    "# user_relation_rdd = tid_users_scores_rdd.flatMap(extract_relations)\n",
    "\n",
    "# # [(u1, [(tid, u2, s1, s2), ...])]\n",
    "# user_relations_rdd = user_relation_rdd.reduceByKey(lambda x, y: x if not x.extend(y) else x)\\\n",
    "#                                       .filter(lambda x:x[1])\n",
    "\n",
    "# # [(u1, [(tid, u2, s1, s2), ...])]\n",
    "# user_best_relations_rdd = user_relations_rdd.map(select_best)\n",
    "\n",
    "# [(u1, [(tid: interest), ...])]\n",
    "# user_interests_rdd = user_best_relations_rdd.map(lambda x: find_user_interests(x, user_scores_dict))\n",
    "\n",
    "# selected_user_interests_rdd = user_interests_rdd.filter(lambda x: x[0] == '933731737686994946')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b8997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(tid, [(u, s)]), ...]\n",
    "tid_user_score_rdd = tweets_rdd.flatMap(lambda x: extract_tuples(json.loads(x), func=to_tid_user_score))\n",
    "\n",
    "# [(tid, [(u, s), ...]), ...]\n",
    "tid_users_scores_rdd = tid_user_score_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# [(u1, (((tid, s1),   [(uj,sj),]),))]\n",
    "user_relation_rdd = tid_users_scores_rdd.flatMap(extract_relations)\\\n",
    "                                      .filter(lambda x:x[1][0][1])\n",
    "\n",
    "# [(u1, (((tid, s1), [(uj,sj),]), ...))]\n",
    "user_relations_rdd = user_relation_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# [(uj, {tid: interest})]\n",
    "user_interests_flat_rdd = user_relations_rdd.flatMap(lambda x: find_user_interests(x))\n",
    "\n",
    "# [(uj, {tid: interest})]\n",
    "user_interests_rdd = user_interests_flat_rdd.reduceByKey(lambda x, y: dict(Counter(x) + Counter(y)))\n",
    "\n",
    "# selected_user_interests_rdd = user_interests_rdd.filter(lambda x: x[0] == '933731737686994946')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de594df-0c31-497a-921d-eaf106de83b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "you must choose user id in this section.\n",
    "you can change # in `list(user_scores_dict.keys())[#]` for this purpose.\n",
    "'''\n",
    "# uid = list(user_scores_dict.keys())[1]\n",
    "uid = users[1]\n",
    "selected_user_interests = user_interests_rdd.filter(lambda x: x[0] == uid).take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a488f1-4957-41ba-b931-affb13fcd918",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "necessary_keys = ['tweet_type', 'user', 'id','text', 'name', 'screen_name', \n",
    "                  'in_reply_to_status_id_str', 'in_reply_to_user_id_str',\n",
    "                  'quoted_status', 'retweeted_status','profile_image_url',\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a247f-cb86-4753-ae79-b6f4feac6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_tweets = tweets_rdd.filter(lambda x: json.loads(x)['id'] in selected_user_interests[0][1].keys() or\n",
    "                                               json.loads(x)['user']['id'] == uid)\\\n",
    "                             .map(lambda x: dict(filter(lambda y: y[0] in necessary_keys, json.loads(x).items())))\\\n",
    "                             .collect()\n",
    "interests_tweets2 = interests_tweets.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d06830-d45a-4f8a-9afa-e92f9142e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_origin_tweets(tweets, uid, rem=True):\n",
    "    origin_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'generated':\n",
    "            if t.get('user',{}).get('id','0') == uid:\n",
    "                origin_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in origin_tweets:\n",
    "            tweets.remove(t)\n",
    "    return origin_tweets\n",
    "\n",
    "\n",
    "def extract_user_replied_tweets(tweets, uid, rem=True):\n",
    "    replied_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'replied':\n",
    "            if t.get('user',{}).get('id','0') == uid:\n",
    "                replied_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in replied_tweets:\n",
    "            tweets.remove(t)\n",
    "    return replied_tweets\n",
    "\n",
    "\n",
    "def extract_user_quoted_tweets(tweets, uid, rem=True):\n",
    "    quoted_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'quoted':\n",
    "            if t.get('user',{}).get('id','0') == uid:\n",
    "                quoted_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in quoted_tweets:\n",
    "            tweets.remove(t)\n",
    "    return quoted_tweets\n",
    "\n",
    "\n",
    "def extract_user_retweeted_tweets(tweets, uid, rem=True):\n",
    "    retweeted_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'retweeted':\n",
    "            if t.get('user',{}).get('id','0') == uid:\n",
    "                retweeted_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in retweeted_tweets:\n",
    "            tweets.remove(t)\n",
    "    return retweeted_tweets\n",
    "\n",
    "\n",
    "def extract_replied_to_user_tweets(tweets, uid, rem=True):\n",
    "    replied_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'replied':\n",
    "            if t.get('in_reply_to_user_id_str', '0') == uid:\n",
    "                replied_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in replied_tweets:\n",
    "            tweets.remove(t)\n",
    "    return replied_tweets\n",
    "\n",
    "\n",
    "def extract_quoted_user_tweets(tweets, uid, rem=True):\n",
    "    quoted_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'quoted':\n",
    "            if t.get('quoted_status', {}).get('user', {}).get('id', '0') == uid:\n",
    "                quoted_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in quoted_tweets:\n",
    "            tweets.remove(t)\n",
    "    return quoted_tweets\n",
    "\n",
    "\n",
    "def extract_retweeted_user_tweets(tweets, uid, rem=True):\n",
    "    retweeted_tweets = []\n",
    "    for t in tweets:\n",
    "        if t['tweet_type'] == 'retweeted':\n",
    "            if t.get('retweeted_status', {}).get('user', {}).get('id', '0') == uid:\n",
    "                retweeted_tweets.append(t)\n",
    "    if rem:\n",
    "        for t in retweeted_tweets:\n",
    "            tweets.remove(t)\n",
    "    return retweeted_tweets\n",
    "\n",
    "\n",
    "def extract_explore_tweets(tweets):\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa1e40-71f3-4526-bd7b-a77db206884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_tweets = interests_tweets2.copy()\n",
    "user_origin_tweets = extract_user_origin_tweets(interests_tweets, uid)\n",
    "user_quoted_tweets  = extract_user_quoted_tweets(interests_tweets, uid)\n",
    "user_retweeted_tweets  = extract_user_retweeted_tweets(interests_tweets, uid)\n",
    "user_replied_tweets  = extract_user_replied_tweets(interests_tweets, uid)\n",
    "replied_to_user_tweets  = extract_replied_to_user_tweets(interests_tweets, uid)\n",
    "quoted_user_tweets  = extract_quoted_user_tweets(interests_tweets, uid)\n",
    "retweeted_user_tweets  = extract_retweeted_user_tweets(interests_tweets, uid)\n",
    "explore_tweets = extract_explore_tweets(interests_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa43eb-b382-4067-a8b7-7271088d273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_origin_tweets: 1 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "تصویری از جنایات جمهوری اسلامی ایران در آبان ۹۸ \n",
      "در همان روزهای اعتراضات تعدادی از جوانان ناپدید شدند و پس از چند روز اجساد آنان دست و پا بسته همراه با آثار شکنجه بر بدن در سدهای مریوان ،سنندج ،خوزستان وکرج پیدا شدند . اسامی تعدادی از این جانباختگان به شرح زیر است:\n",
      "عرفان ساعدپناه \n",
      "ارشاد رحمانیان \n",
      "هیوا رحیمی \n",
      "مسعود امینی \n",
      "رضا صادقی\n",
      "سوران محمدی \n",
      "علی جواهری \n",
      "#نه_میبخشیم_نه_فراموش_میکنیم \n",
      "#آبان_۹۸\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_origin_tweets:', len(user_origin_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_origin_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42433ba8-55d0-45fc-98a5-64d2afdcebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_quoted_tweets: 3 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "بجای درست کردن «حزب»های کارتونی برای کردستان، بروید کمی از مبارزه کردها، مقاومتشان، سازماندهیشان، شهامتشان و مبارزات سکولار، جدی و استخواندار آنها یاد بگیرید. شما تنها کاری که میتوانید بکنید این است که به سخنرانی مانیفستوار مادران و پدران کردستان بر مزار عزیزانشان، گوش بدهید. و کمی فرهنگ سیاسی، کمی مبارزه، کمی شهامت و کمی آزادگی بیاموزید. کردستان، توییتر فارسی نیست.\n",
      "#ژن_ژیان_ئازادی \n",
      "#ژینا_امینی\n",
      "----------------------------------------------------------------------------------------------------\n",
      "جمهوری اسلامی پیشمرگ مسلمان کرد درست کرد.\n",
      "رضا پهلوی فرمان تاسیس حزب کردی داد.\n",
      "در هر حال برای ما هر دو گروه جاش هستند. https://t.co/WautxEriQF\n",
      "----------------------------------------------------------------------------------------------------\n",
      "بجای درست کردن «حزب»های کارتونی برای کردستان، بروید کمی از مبارزه کردها، مقاومتشان، سازماندهیشان، شهامتشان و مبارزات سکولار، جدی و استخواندار آنها یاد بگیرید. شما تنها کاری که میتوانید بکنید این است که به سخنرانی مانیفستوار مادران و پدران کردستان بر مزار عزیزانشان، گوش بدهید\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_quoted_tweets:', len(user_quoted_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_quoted_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c80bce-19f8-4319-a462-225f73fd4b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_retweeted_tweets: 4 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "سوزش #فرقه_پهلوی بخاطر رقص گلشیفته  نیست\n",
      "بخاطر این تصویر و همدلی بین این افراده!\n",
      " رسانه های سپاه را هم نگاه کنید و با رفتار این فرقه مقایسه کنید!\n",
      "هیچ چیز اتفاقی نیست\n",
      "هیچ چیز عادی نیست!\n",
      "یک روز #روح_الله_زم  را تخریب کردند\n",
      "یک روز...\n",
      "#مهسا_امينی https://t.co/XZ8ZRvoDEs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "شبهات قانونی حکم اعدام #محسن_شکاری \n",
      "\n",
      "اجرای حکم اعدام ،تنها ۱۸ روز پس از صدور ،موجی از واکنشها و محکومیت را در پی داشت.در اینکه اعدام او قانونی بود یا خیر باید گفت چون اتهام وی بستن خیابان ستارخان و مجروح کردن یک عضو نیروی بسیج بود، رای هم شبهه موضوعی دارد و هم شبهه حکمی!؟ ۱\n",
      "----------------------------------------------------------------------------------------------------\n",
      "جنایاتی که مرتکب شدەاید، خونهایی که ریختە و قصاوتی که داشتەاید را هزاران بار دیگر یادآوری میکنیم. به همه مردمان جهان نشان میدهیم که شما آدمکشان رسالتی جز خونریزی، قتل و اعدام نداشتید. اینها تصاویری است که هر کدام صدها زندگی را آغشته به اندوه کرده است ۱/۴\n",
      "#آنچه_باقی_ماند https://t.co/YHbjcAyYAG\n",
      "----------------------------------------------------------------------------------------------------\n",
      "این حساسیت هیستریک بە حضور عبدالله مهتدی در  مراسم اهدای صلح نوبل هیچ نشانه مثبتی برای همزیستی مسالمت آمیز و دمکراتیک در یک ایران یکپارچە نیست این حجم از تنفر در میدان عمل نتیجەای جزء کشتار و قتل عام ندارد علی رغم میل باطنیم باید بگوییم کە کردها و دیگر ملیتها باید اسناد و مدارک ستم مضاعف و نیز اینحجم  تنفر کینە توزی اپوزیسیون را جمعاوری کنند و در مجامع بین المللی بە دنبال جدایی کامل از ایران باشند و خود را برای نبرد نهایی آمادە کنند\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_retweeted_tweets:', len(user_retweeted_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_retweeted_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fcb9f-f412-4cb6-a82e-09fd0a5209be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_replied_tweets: 6 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@KeyOne367 عین شبکه من و تو از قبل همه رو انتخاب کردند\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@fariba312 @SGhasseminejad انقدر سرشون تو اخور پهلویه نمیدونن چی به چیه 😁\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@KambizGhafouri @fariba312 خوب شد رضا شاه مرد و این روزها زو ندید وگرنه رضا پهلوی رو درجا خنثی میکرد\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@2Ubbe برای گذار از جمهوری اسلامی با احدی تعارف نداریم ولی به نظرم این متن نوشته شده بیشتر از روی احساسات توسط یک سری از خانواده های دادخواه پخش شد و نمیدانستند اصل داستان از چه سمتی است\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@joker_yaghi67 کی فکرش رو میکرد عاقبت سلطنت پهلوی به اینجا برسه\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@joker_yaghi67 واقعا رضا قلدر کجا ،رضا پخمه کجا 😉\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_replied_tweets:', len(user_replied_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_replied_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e410b2-a68f-4fa1-a7dd-1b2a8400596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of explore_tweets:  3 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t ۲۱ آذر ۱۳۳۷ (۱۲ سال پس از #نجات_آذربایجان از هاضمه شوروی) دو رژه در تهران و تبریز بنام \"جشن ارتش ایران\"  برگزار شد. اینها از نخستین قدم هایی بود که ارتش نو نَوا شده ایران بر روی زمین می کوبید.\n",
      "\t  میراث رضاشاه که با آن شیخ خزعل و سیمیتقو  را درهم کوبیده بود، با قطع ید ریزه خواران استالین در آذربایجان و مهاباد دوباره جان گرفت، سپس برای کمک به پادشاه عمان به جنگ دست نشاندگان شوروی در ظفار رفت و بعد مهمترین شریک ایالات متحده در پروژه های اطلاعاتی آیبکس و ژن تیره شد.\n",
      "\t از میانه دهه ۷۰، این ارتش جوان اما مدرن و آموزش دیده، پنجمین قدرت نظامی دنیا بود که پس از سالها مناقشه به توهمات صدام حسین بر سر اروند رود و خوزستان پایان داد.\n",
      "\t راهی کوتاه، اما سخت و طاقت فرسا در محاصره گرگ ها و کفتاران و خائنان طی شد، تا ارتش نوپای رضاشاه به آنجا رسید!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t من این کلیپ رو برای تبلیغ یا آموزش برندسازی نزدم\n",
      "\t \n",
      "\t میخوام بگم آدم زرنگ و باهوش و زیرک و متفکر کسی هست که حتی از اشتباهات دیگران (و خودش) درس عبرت بگیره و دست از تکرار مسیرهای منتهی به شکست برداره\n",
      "\t \n",
      "\t بیایید ۵۷ و عواملش را پشت سر بگذاریم\n",
      "\t و از هرگونه جریان ۵۷ ساز دوری بجوییم\n",
      "\t تنها راه https://t.co/TQwgpdTxxg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t من این کلیپ رو برای تبلیغ یا آموزش برندسازی نزدم\n",
      "\t \n",
      "\t میخوام بگم آدم زرنگ و باهوش و زیرک و متفکر کسی هست که حتی از اشتباهات دیگران (و خودش) درس عبرت بگیره و دست از تکرار مسیرهای منتهی به شکست برداره\n",
      "\t \n",
      "\t بیایید ۵۷ و عواملش را پشت سر بگذاریم\n",
      "\t و از هرگونه جریان ۵۷ ساز دوری بجوییم\n",
      "\t تنها راه https://t.co/TQwgpdTxxg\n"
     ]
    }
   ],
   "source": [
    "print('Number of explore_tweets: ', len(explore_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in explore_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print('\\t',line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083dbfb-345c-453b-9a63-df6efb751164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 23:21:17.127248\n"
     ]
    }
   ],
   "source": [
    "endt = datetime.datetime.now()\n",
    "print(endt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504bb8a",
   "metadata": {},
   "source": [
    "# User Recommender "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9a7a6",
   "metadata": {},
   "source": [
    "### Define the functions required to perform Min-Hashing and LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d68f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hash(x, i, N):\n",
    "    '''\n",
    "        random_a and random_b are a list of random integers\n",
    "        p is a prime number that bigger than 32^7-1\n",
    "    '''\n",
    "    return ((my_hash.random_a[i] * x + my_hash.random_b[i]) % my_hash.p) % N \n",
    "\n",
    "\n",
    "def signature(tweet_list):\n",
    "    '''\n",
    "    This function performs Min-Hashing on tweet_list like \n",
    "    One-pass implementation which is mentioned in the slides\n",
    "    and return signature vector (as a list)\n",
    "    M is length of the vector that equals to r*b\n",
    "    BTI is the Biggest Tweet ID \n",
    "    '''\n",
    "    sig = [signature.BTI+1 for _ in range(signature.M)]\n",
    "    \n",
    "    for j in tweet_list:\n",
    "        for i in range(signature.M):\n",
    "            k = my_hash(j, i, signature.BTI)\n",
    "            if k < sig[i]:\n",
    "                sig[i] = k\n",
    "    return sig\n",
    "\n",
    "\n",
    "# It is not used in this script\n",
    "def bands_hashing_lossless(x): \n",
    "    '''This function hashes r numbers into one big number without losing data'''\n",
    "    out = 0\n",
    "    for i in range(int(lsh.r)):\n",
    "        out *= bands_hashing.NBOR\n",
    "        out += x[i] % bands_hashing.NBOR\n",
    "    return out\n",
    "\n",
    "\n",
    "def bands_hashing(x): \n",
    "    '''This function hashes r numbers into sum of them (less than NBOR)'''\n",
    "    out = 0\n",
    "    for i in range(int(lsh.r)):\n",
    "        out += x[i]\n",
    "    return out % bands_hashing.NBOR\n",
    "\n",
    "\n",
    "def lsh(sig):\n",
    "    '''This function drops each signature(sig) into b buckets'''\n",
    "    return [bands_hashing(sig[i*lsh.r : (i+1)*lsh.r]) for i in range(lsh.b)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a268d04",
   "metadata": {},
   "source": [
    "### Define parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcbed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divide signature matrix into <10> bands of <3> rows\n",
      "\n",
      "list of random integers for a and b in my hashing formula(ax+b):\n",
      "a:  [157, 112, 240, 225, 214, 171, 152, 379, 144, 316, 116, 115, 147, 211, 219, 358, 113, 387, 201, 379, 314, 212, 329, 242, 103, 181, 316, 274, 242, 179]\n",
      "\n",
      "b:  [56, 196, 87, 27, 24, 98, 25, 92, 89, 155, 68, 12, 187, 118, 138, 32, 97, 21, 142, 76, 161, 159, 93, 148, 50, 181, 18, 12, 170, 59]\n"
     ]
    }
   ],
   "source": [
    "signature.BTI = 100000000  # 2000000000000000000  # BTI is the Biggest Tweet ID \n",
    "bands_hashing.NBOR = signature.BTI  # Number of Bucket for One Row\n",
    "\n",
    "r = 3  # Number of rows in Signature matrix\n",
    "b = 10  # Number of bands in Signature matrix\n",
    "M = r * b  # Signature size for each news\n",
    "lsh.r = r\n",
    "lsh.b = b\n",
    "signature.M = M\n",
    "print(f'Divide signature matrix into <{b}> bands of <{r}> rows')\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "my_hash.random_a = [random.randint(100, 400) for i in range(M)]\n",
    "my_hash.random_b = [random.randint(1, 200) for i in range(M)]\n",
    "my_hash.p = 104677207  # 2015121110987654321\n",
    "print('\\nlist of random integers for a and b in my hashing formula(ax+b):')\n",
    "print('a: ', my_hash.random_a)\n",
    "print('\\nb: ', my_hash.random_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving all tweets that each user is interested in as a list (bag of tweets)\n",
    "# user_interests_rdd: [(u1, [(tid: interest), ...])]\n",
    "user_tweets_bag_rdd = user_interests_rdd.filter(lambda x: x[1])\\\n",
    "    .map(lambda x: (x[0], [int(tid) % signature.BTI for tid in x[1].keys()]))  # [(u1, [tid, ...])]\n",
    "\n",
    "# Retrieving the users of every buckets\n",
    "bucket_user_rdd = user_tweets_bag_rdd.flatMap(lambda x: [(bucket, {x[0]}) for bucket in lsh(signature(x[1]))])  # (bucket, uid)\n",
    "\n",
    "bucket_users_rdd = bucket_user_rdd.reduceByKey(lambda x, y: x.union(y))  # (bucket, uids)\n",
    "\n",
    "# [(bucket, {users})]  # a list of b bucket\n",
    "bucket_candidate_uids = bucket_users_rdd.filter(lambda x: uid in x[1]).take(lsh.b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f74695",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_candidate_uids = bucket_users_rdd.filter(lambda x: uid in x[1]).take(lsh.b)\n",
    "bucket_candidate_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf1c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21052469, {'1425068264862978049'}),\n",
       " (9161032,\n",
       "  {'1348410757298458624',\n",
       "   '1425068264862978049',\n",
       "   '1445120935141466112',\n",
       "   '1572861549991104512',\n",
       "   '1601767356837117952',\n",
       "   '918911124254416901'}),\n",
       " (11292176, {'1425068264862978049'}),\n",
       " (1700380,\n",
       "  {'1341775133032198145',\n",
       "   '1348410757298458624',\n",
       "   '1425068264862978049',\n",
       "   '1445120935141466112',\n",
       "   '1572861549991104512',\n",
       "   '1601767356837117952',\n",
       "   '917647599762632704',\n",
       "   '918911124254416901'}),\n",
       " (47937934,\n",
       "  {'1425068264862978049', '1445120935141466112', '918911124254416901'}),\n",
       " (29465416,\n",
       "  {'1425068264862978049', '1445120935141466112', '918911124254416901'}),\n",
       " (9570192,\n",
       "  {'1425068264862978049', '1445120935141466112', '918911124254416901'}),\n",
       " (16193730,\n",
       "  {'1425068264862978049', '1445120935141466112', '918911124254416901'}),\n",
       " (3354056,\n",
       "  {'1425068264862978049',\n",
       "   '1445120935141466112',\n",
       "   '1643014199814025217',\n",
       "   '918911124254416901',\n",
       "   '989887176803528704'}),\n",
       " (20684908,\n",
       "  {'1425068264862978049', '1445120935141466112', '918911124254416901'})]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_candidate_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78978b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1341775133032198145',\n",
       " '1348410757298458624',\n",
       " '1425068264862978049',\n",
       " '1445120935141466112',\n",
       " '1572861549991104512',\n",
       " '1601767356837117952',\n",
       " '1643014199814025217',\n",
       " '917647599762632704',\n",
       " '918911124254416901',\n",
       " '989887176803528704'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_users = set()\n",
    "for _, uids in bucket_candidate_uids:\n",
    "    candidate_users = candidate_users.union(uids)\n",
    "\n",
    "candidate_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50883aea",
   "metadata": {},
   "source": [
    "### Define the functions required to show similar condidate and similar news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilars(cus, q_uid, threshold=0.4):\n",
    "    ''' \n",
    "    This function get shingles of candidate news, calculate similarity\n",
    "    of candidate news with query news and it returns news whose ratio \n",
    "    of common shingles with query news to the union of their shingles is \n",
    "    greater than threshold.\n",
    "\n",
    "    cus: candidate users' shingles, a list of (uid, [shingle_id])\n",
    "    q_uid: uid of query user\n",
    "    '''\n",
    "    q_shingles = []\n",
    "    for i in range(len(cus)):\n",
    "        if q_uid == cus[i][0]:\n",
    "            q_shingles = list(cus[i][1])\n",
    "            break\n",
    "        \n",
    "    similars = []\n",
    "    for candidate in cus:\n",
    "        # s is Jaccard similarity of news = (query_news ∩ candidate_news)/union(query_news U candidate_news)\n",
    "        s = len(set(candidate[1])&set(q_shingles))/len(set(candidate[1])|set(q_shingles))\n",
    "        if s >= threshold:    \n",
    "            similars.append((candidate[0], s)) # a list of (uid, percent)\n",
    "\n",
    "    return similars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd3c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "you must choose user_id (uid) in this section.\n",
    "you can change # in 'user_buckets[#][0]' for this purpose.\n",
    "\"\"\"\n",
    "q_uid = uid\n",
    "\n",
    "# Retrieving all tweets that each user is interested in as a list (bag of tweets)\n",
    "# candidate_user_shingles: a list of (uid, [shingle_id])\n",
    "candidate_user_shingles = user_tweets_bag_rdd.filter(lambda x: x[0] in candidate_users)\\\n",
    "                                             .collect()\n",
    "\n",
    "# similar: a list of (uid, percent of similarity)\n",
    "similar = getSimilars(candidate_user_shingles, q_uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7aa3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "similar_uids, similarites = zip(*similar)\n",
    "\n",
    "interests_tweets = tweets_rdd.filter(lambda x: json.loads(x)['user']['id'] in similar_uids)\\\n",
    "                             .map(lambda x: dict(filter(lambda y: y[0] in necessary_keys, json.loads(x).items())))\\\n",
    "                             .collect()\n",
    "interests_tweets2 = interests_tweets.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0533457",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03myou must select id of similar user (similar_uid) in this section.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03myou can change # in 'similar_uids[#]' for this purpose.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m similar_uid \u001b[38;5;241m=\u001b[39m \u001b[43msimilar_uids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "you must select id of similar user (similar_uid) in this section.\n",
    "you can change # in 'similar_uids[#]' for this purpose.\n",
    "\"\"\"\n",
    "similar_uid = similar_uids[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_tweets = interests_tweets2.copy()\n",
    "user_origin_tweets = extract_user_origin_tweets(interests_tweets, similar_uid, rem=False)\n",
    "user_quoted_tweets  = extract_user_quoted_tweets(interests_tweets, similar_uid, rem=False)\n",
    "user_retweeted_tweets  = extract_user_retweeted_tweets(interests_tweets, similar_uid, rem=False)\n",
    "user_replied_tweets  = extract_user_replied_tweets(interests_tweets, similar_uid, rem=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93846579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_origin_tweets: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_origin_tweets:', len(user_origin_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_origin_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_quoted_tweets: 1 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "نرگس محمدی مثالی از «استقامت سازنده» است زیرا نه به تقیه و تسلیم تن میدهد و نه همچون بعضی مخالفانِ ج.ا از همان «سیاست کثیفِ» ستمگران حاکم (خودمحقپنداریِ جزماندیشانه،خشونتستایی،نارواداری،انحصارطلبی،دروغگویی و تهمتپراکنی) پیروی میکند.او قیدوبندهای اخلاقی را به رسمیت میشناسد\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_quoted_tweets:', len(user_quoted_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_quoted_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_retweeted_tweets: 1 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "بجای درست کردن «حزب»های کارتونی برای کردستان، بروید کمی از مبارزه کردها، مقاومتشان، سازماندهیشان، شهامتشان و مبارزات سکولار، جدی و استخواندار آنها یاد بگیرید. شما تنها کاری که میتوانید بکنید این است که به سخنرانی مانیفستوار مادران و پدران کردستان بر مزار عزیزانشان، گوش بدهید. و کمی فرهنگ سیاسی، کمی مبارزه، کمی شهامت و کمی آزادگی بیاموزید. کردستان، توییتر فارسی نیست.\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_retweeted_tweets:', len(user_retweeted_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_retweeted_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user_replied_tweets: 4 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@aghferiii @andfogle سال 1302، مدرس رو به رضا خان سردار سپه وقت:\n",
      "\"...پس چرا باید طوری صحبت کنی که آدم یاد بسیجی های چاق و احمق بیوفته؟\" https://t.co/HDMUuVBqQm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@_essisajjad چطور نیستی وقتی سَرت اینطور تو کون دیگرانه؟!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@hamshahrinews چه بازی تکراریی. ج.ا تا میبینه در مقابله مستقیم ضعف داره و حمله مستقیمش کاری نیست، سریع تمرکزش رو میبره روی اینکه به گروه های مخالفش بگه \"نگاه کنید چقدر رقیب همین، نگاه اَاا چطور این اون رو ناک اوت کرد، نگاه چه شکاف عمیقی بینتون هست، چقــــــــــــــدر اختلاف دارین شماها، پشمام!\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "@Me_Unstoppable2 یعنی اگه آمریکا برای یک جایزه ای یا چیزی، رضا پهلوی رو دعوت کنن به \"ساختمان کنگره\" یا \"کاخ سفید\" و \"رییس جمهور\" و \"بانوی اول\" حضور داشته باشن و از رضا پهلوی استقبال کنن، بهتون بر میخوره و کونتون کج میشه و از جمهور خواه ها قبول میکنن که بگن \"میثل اینکی ویرژین ایرینیش خار داره\"!\n"
     ]
    }
   ],
   "source": [
    "print('Number of user_replied_tweets:', len(user_replied_tweets), '\\n')\n",
    "ts = [t['text'].replace('\\u200c', '').split('\\n') for t in user_replied_tweets]\n",
    "for t in ts:\n",
    "    print('-'*100)\n",
    "    for line in t:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005b1e6-7185-44f2-b220-b5ba69daf7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sys.getsizeof(tweets)\n",
    "sys.getsizeof(explore_tweets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
